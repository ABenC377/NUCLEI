

___Lexical parser testing___

The following functions are assert tested in the lexical_parse_test() function as described:
- get_file_name()
    This function takes argc and argv as inputs, and outputs the file name if one is provided as an argv argument.  To check this, it looks for an argument that has a '.' in a non-final position.  If there are more than one file names provided, then the function returns the first file name provided.  If there are no file names provided, then the function returns NULL.  To test this function, I have assert tested that it provides the correct file name when given sets of argv strings that contain a valid file name, and NULL when it isn't.

- update_tokens()
    This function takes in the pre-made token-list, FSM automata, and a character.  The behavious is dictated by the state of the automata, and c.  Therefore, I test it with an automata in every state, and for each state, each type of character (e.g., each type of expected character, and imaginable unexpected characters).

- add_previous_chars()
    This function is for backtracking when you have already recieved a number of letters of a reserved word (e.g., WHILE) and then recieved an unexpected character.  It does this by adding the first letter of the reserved word as a variable token to the token list, and then considering the following letters in order as if they were newly input characters.  To test this function, I checked that the function correctly adds the variable to a token list, and then seperately that it correctly adds the following characters (either as variables or as different reserved words).

- make_and_add_simple_token()
    This function makes a token of a given type, adds it to the tokens list, and resets the automata to its start state.  It only works for token types that don't have additional information (i.e., all but literal, string and variable token types).  I have tested this function against each of the simple token types to check that it successfully adds a token of that type to the token list.  This function is only ever called when a simple token is to be added, and so there is no need to test it with complex token type inputs.

- handle_start_state()
    This function checks the character that is provided from the file, and handles it correctly.  There are five types of valid characters according to the grammar of NUCLEI: 1) white space - this should be ignored; 2) parentheses - these are individual tokens and should be added to the token list; 3) a single quote - this signifies the beginning of a literal; 4) a double quote - this signifies the beginning of a string; and 5) a capitalised letter - this is either a variable or the beginning of a reserved word, and should be handled accordingly.  If the character is none of these, then the function adds an 'invalid' token to the token list.  To test this function, I have assert tested it with characters of each of the above types (including invalid) to ensure that they are handled correctly.
    This function is only called from update_tokens(), when the automata is in the start state.  It is passed the tokens and automata arguments directly from the arguments of this higher function.  Therefore, we do not need to check that these arguments are valid, because this has been checked higher up.  Therefore, I have not tested for this.

- add_variable_token()
    This function adds a token of type variable to the token list.  The name of the variable (i.e., A-Z) is provided as an input.  I've tested this function against each possible varibale name to confirm that a correctly named token is added to the token list.  
    This function is only called in add_previous_chars() and handle_start_state().  in add_previous_chars(), it is called in relation to the var argument, which is only ever a capitalised letter (see the switch statement in update_tokens()).  In handle_start_state(), this function is only called in the event of a character that is A-Z.  Therefore, we know that this function is only ever called with a name that is valid (i.e., A-Z).  Therefore, we do not need to handle incorrect names, and I have not tested for this.
    Similarly, because the tokens and automata arguments of this function are always passed directly from the arguments of the functions that call it (i.e., add_previous_chars() and handle_start_state()), we know that they must be valid (otherwise the higher up functions would have failed).  Therefore, I have not tested for this.

- handle_in_state()
    

- add_token()
    


The following functions rely on command line arguments and reading from files, and so are not testable with quiet assert testing:
- run_lexiacl_analyser()
- get_tokens_from_file()

The following functions are structure-specific print functions, and are only used for debugging etc., so are not testable with quiet assert testing:
- print_tokens()
- print_token()

The following functions are used in the lexical_parse_test() function, but are not directly assert tested.  However, they free the memory allocated to the structures made for testing the other functions, and using Valgrind it is seen that running lexical_parse_test() does not result in any memory leaks.  Therefore, we can see that these functions work as intended:
- free_token_list()
- free_token_node()